{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c18982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.11).\n",
      "Resuming download from 3185573888 bytes (14026199359 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/mohammedabdeldayem/the-fake-or-real-dataset?dataset_version_number=2 (3185573888/17211773247) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.0G/16.0G [27:01<00:00, 8.65MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mohammedabdeldayem/the-fake-or-real-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984abf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# âœ… STEP 1: Dataset Paths (Change if needed)\n",
    "base_path = r\"C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\"\n",
    "train_dir = os.path.join(base_path, \"for-norm\", \"for-norm\", \"training\")\n",
    "val_dir = os.path.join(base_path, \"for-norm\", \"for-norm\", \"validation\")\n",
    "test_dir = os.path.join(base_path, \"for-rerec\", \"for-rerecorded\", \"testing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa61f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, n_mfcc=13):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        if len(audio) < 2048:\n",
    "            print(f\"âš ï¸ Skipping short file: {file_path}\")\n",
    "            return None\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error with {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# âœ… STEP 3: Dataset Loader\n",
    "def load_dataset(folder):\n",
    "    X, y = [], []\n",
    "    for label_name, label_val in [('real', 0), ('fake', 1)]:\n",
    "        label_path = os.path.join(folder, label_name)\n",
    "        for fname in os.listdir(label_path):\n",
    "            if fname.endswith('.wav'):\n",
    "                fpath = os.path.join(label_path, fname)\n",
    "                feat = extract_features(fpath)\n",
    "                if feat is not None:\n",
    "                    X.append(feat)\n",
    "                    y.append(label_val)\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54695561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading datasets...\n",
      "âš ï¸ Skipping short file: C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\\for-norm\\for-norm\\training\\real\\file11064.wav_16k.wav_norm.wav_mono.wav_silence.wav\n",
      "âš ï¸ Skipping short file: C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\\for-norm\\for-norm\\training\\real\\file15440.wav_16k.wav_norm.wav_mono.wav_silence.wav\n",
      "âš ï¸ Skipping short file: C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\\for-norm\\for-norm\\training\\real\\file15932.wav_16k.wav_norm.wav_mono.wav_silence.wav\n",
      "âš ï¸ Skipping short file: C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\\for-norm\\for-norm\\training\\fake\\file2846.wav_16k.wav_norm.wav_mono.wav_silence.wav\n",
      "âš ï¸ Skipping short file: C:\\Users\\91986\\.cache\\kagglehub\\datasets\\mohammedabdeldayem\\the-fake-or-real-dataset\\versions\\2\\for-norm\\for-norm\\validation\\real\\file16316.wav_16k.wav_norm.wav_mono.wav_silence.wav\n"
     ]
    }
   ],
   "source": [
    "# âœ… STEP 4: Load Train/Validation/Test Data\n",
    "print(\"ðŸ“¦ Loading datasets...\")\n",
    "X_train, y_train = load_dataset(train_dir)\n",
    "X_val, y_val = load_dataset(val_dir)\n",
    "X_test, y_test = load_dataset(test_dir)\n",
    "\n",
    "# âœ… STEP 5: Model Candidates\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(kernel='rbf', probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95396a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training RandomForest...\n",
      "âœ… RandomForest Accuracy on Validation Set: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      5399\n",
      "           1       0.97      0.98      0.97      5398\n",
      "\n",
      "    accuracy                           0.97     10797\n",
      "   macro avg       0.97      0.97      0.97     10797\n",
      "weighted avg       0.97      0.97      0.97     10797\n",
      "\n",
      "\n",
      "ðŸš€ Training LogisticRegression...\n",
      "âœ… LogisticRegression Accuracy on Validation Set: 0.7699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      5399\n",
      "           1       0.77      0.77      0.77      5398\n",
      "\n",
      "    accuracy                           0.77     10797\n",
      "   macro avg       0.77      0.77      0.77     10797\n",
      "weighted avg       0.77      0.77      0.77     10797\n",
      "\n",
      "\n",
      "ðŸš€ Training SVM...\n",
      "âœ… SVM Accuracy on Validation Set: 0.8681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87      5399\n",
      "           1       0.86      0.88      0.87      5398\n",
      "\n",
      "    accuracy                           0.87     10797\n",
      "   macro avg       0.87      0.87      0.87     10797\n",
      "weighted avg       0.87      0.87      0.87     10797\n",
      "\n",
      "\n",
      "ðŸš€ Training KNN...\n",
      "âœ… KNN Accuracy on Validation Set: 0.9616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      5399\n",
      "           1       0.95      0.98      0.96      5398\n",
      "\n",
      "    accuracy                           0.96     10797\n",
      "   macro avg       0.96      0.96      0.96     10797\n",
      "weighted avg       0.96      0.96      0.96     10797\n",
      "\n",
      "\n",
      "ðŸš€ Training GradientBoosting...\n",
      "âœ… GradientBoosting Accuracy on Validation Set: 0.8932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      5399\n",
      "           1       0.89      0.90      0.89      5398\n",
      "\n",
      "    accuracy                           0.89     10797\n",
      "   macro avg       0.89      0.89      0.89     10797\n",
      "weighted avg       0.89      0.89      0.89     10797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… STEP 6: Train & Evaluate Models\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸš€ Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    results.append((name, acc, model))\n",
    "    print(f\"âœ… {name} Accuracy on Validation Set: {acc:.4f}\")\n",
    "    print(classification_report(y_val, val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336caeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best Model: RandomForest (Accuracy: 0.9738)\n",
      "ðŸ’¾ Saved best model as: best_model_RandomForest.pkl in c:\\Users\\91986\\Desktop\\DSPL MPR\n",
      "\n",
      "ðŸ§ª Final Evaluation on Rerecorded Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.48      0.63       408\n",
      "           1       0.65      0.96      0.78       408\n",
      "\n",
      "    accuracy                           0.72       816\n",
      "   macro avg       0.79      0.72      0.70       816\n",
      "weighted avg       0.79      0.72      0.70       816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… STEP 7: Pick Best Model\n",
    "best_model = max(results, key=lambda x: x[1])\n",
    "best_name, best_acc, best_model_instance = best_model\n",
    "print(f\"\\nðŸ† Best Model: {best_name} (Accuracy: {best_acc:.4f})\")\n",
    "\n",
    "# âœ… STEP 8: Save Model in Same Folder as Notebook\n",
    "notebook_dir = os.getcwd()\n",
    "model_filename = f\"best_model_{best_name}.pkl\"\n",
    "model_path = os.path.join(notebook_dir, model_filename)\n",
    "joblib.dump(best_model_instance, model_path)\n",
    "print(f\"ðŸ’¾ Saved best model as: {model_filename} in {notebook_dir}\")\n",
    "\n",
    "# âœ… STEP 9: Final Evaluation on Rerecorded Test Set\n",
    "print(\"\\nðŸ§ª Final Evaluation on Rerecorded Test Set:\")\n",
    "test_pred = best_model_instance.predict(X_test)\n",
    "print(classification_report(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca60eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
